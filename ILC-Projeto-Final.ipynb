{"cells":[{"cell_type":"markdown","source":"# Introdução à Linguística Computacional\n\n## Análise de textos jornalísticos e artigos científicos sobre enchentes na cidade de São Paulo","metadata":{"tags":[],"cell_id":"89cac629589347f89a84ec8a776e0739","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Por:     | \n-------- | -----\nAndré Bernardino Cardim| 11000515\nBianca Miyata Ranieri    | 11042615\nHenrique Queiroz Reuter     | 11201812261","metadata":{"tags":[],"cell_id":"bb5f37a6fbf74ff28c99a83717b51565","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport nltk\nimport requests\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom nltk.tokenize import sent_tokenize\nimport matplotlib\nimport matplotlib.pyplot as plt\nnltk.download('punkt')","metadata":{"tags":[],"cell_id":"91c3b9b845e54406918de25387186e77","source_hash":"57d306e3","output_cleared":true,"execution_start":1619031714337,"execution_millis":3397,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pdfminer\nfrom pdfminer.high_level import extract_text\n\nprint(pdfminer.__version__)  ","metadata":{"tags":[],"cell_id":"db33846568df4c20bb43d457c4250bc2","source_hash":"812651d2","output_cleared":true,"execution_start":1619031717823,"execution_millis":50,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip3 install newspaper3k\n!pip3 install pdfminer.six","metadata":{"tags":[],"cell_id":"401248b4363a4702a7dccc83f863936d","source_hash":"c6d1aad3","output_cleared":true,"execution_start":1619031717868,"execution_millis":5112,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparação dos arquivos .txt para jornalisticos e científicos","metadata":{"tags":[],"cell_id":"c1ed1874765a4bf3888b7114de1f97f9","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Textos jornalísticos\nUtilizando a biblioteca newspaper, acessar cada URL presente no arquivo 'urls_j.txt' e salvar o conteúdo do artigo jornalístico em um arquivo (número)j.txt na pasta 'textos-jornalisticos'","metadata":{"tags":[],"cell_id":"2aa42fa6b6e647fb93d2c81abc30b1ca","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Importar a ferramenta\nfrom newspaper import Article\n \n#Ler cada linha do arquivo txt e colocar na lista 'urls'\nwith open(\"urls_j.txt\") as file:\n    urls = file.read().splitlines()\n\n#Para cada url pegar o titulo+texto e salvar em um arquivo .txt\ni=0\nwhile(i<26):\n     download and parse article\n    article = Article(urls[i])\n    article.download()\n    article.parse()\n\n    file = open('textos-jornalisticos/{}j.txt'.format(i+1), 'w')\n    file.write(article.title+\"\\n\")\n    file.write(article.text)\n    file.close()\n\n    i = i + 1","metadata":{"tags":[],"cell_id":"c5f2a1469a5d49a9ad23dcc1e8d5b419","source_hash":"827374ab","is_code_hidden":false,"execution_start":1619031722980,"execution_millis":7,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Textos científicos\nUtilizando o pdfminer, extrair o texto de cada artigo científico no formato .pdf da pasta 'pdfs-nao-convertidos' e salvar em um arquivo (número)c.txt na pasta 'pdfs-convertidos'","metadata":{"tags":[],"cell_id":"444388f1a085438281105003b5739fc6","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"i = 1\nwhile(i<=9):\n    text = extract_text('pdfs-nao-convertidos/{}c.pdf'.format(i))\n    file = open('pdfs-convertidos/{}c.txt'.format(i), 'w')\n    file.write(text)\n    file.close()\n    i = i + 1","metadata":{"tags":[],"cell_id":"08f4a069602b4edfab68b53b71dbb714","source_hash":"95e2fe88","execution_start":1619031722988,"execution_millis":11,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Criação dos corpus jornalístico e científico\nUtilizando o PlaintextCorpusReader, criar o corpus jornalístico e científico e mostrar 3 das principais informações deles:","metadata":{"tags":[],"cell_id":"3908ebc695ea49a698845fc0c283d316","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import os\nimport nltk\nfrom nltk.corpus import PlaintextCorpusReader\nfrom nltk.corpus import stopwords\n\n#Corpus jornalistico\n\ncorpus_j_path= 'textos-jornalisticos/'\n\ncorpus_j = PlaintextCorpusReader(corpus_j_path, '.*')\n\nprint('O corpus jornalístico tem', len(corpus_j.fileids()), 'textos,', \nlen(corpus_j.words()), 'palavras e', len(corpus_j.sents()), 'sentenças')\n\n#Corpus científico\n \ncorpus_c_path= 'pdfs-convertidos/'\n\ncorpus_c = PlaintextCorpusReader(corpus_c_path, '.*')\n\nprint('O corpus científico tem', len(corpus_c.fileids()), 'textos,', \nlen(corpus_c.words()), 'palavras e', len(corpus_c.sents()), 'sentenças')","metadata":{"tags":[],"cell_id":"b438f511912e40f2a0e9f08c31d57a92","source_hash":"623c3b1c","output_cleared":true,"execution_start":1619031722999,"execution_millis":1420,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Calcular a diversidade lexical de ambos os corpus:","metadata":{"tags":[],"cell_id":"cc692026e6e04766b4288804b60952aa","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Cálculo da diversidade lexical\ndef lexical_diversity(texto):\n    return len(set(texto)) / len(texto)\n\nprint(\"Diversidade do corpus jornalístico:\", \n    100*lexical_diversity(corpus_j.words()), '%')\n\nprint(\"Diversidade do corpus científico:\",\n     100*lexical_diversity(corpus_c.words()), '%')","metadata":{"tags":[],"cell_id":"e5a49d6b16644e2ebe84b9526ddd6357","source_hash":"ba2e25b9","output_cleared":true,"execution_start":1619031724422,"execution_millis":335,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Análise dos corpus pelo analisador morfológico CoGrOO\nImportação do biblioteca para utilização (disponibilizada pela interface CoGrOO4Py), e teste com uma frase simples:","metadata":{"tags":[],"cell_id":"0272cdcce6b74419acecdc509c8be782","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from cogroo_interface import Cogroo\ncogroo = Cogroo.Instance()","metadata":{"tags":[],"cell_id":"266314f265ae4f64822e0aec50be558e","source_hash":"9e7b18d","execution_start":1619031724758,"execution_millis":10,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Definição da lista de classficiações morfológicas válidas:","metadata":{"tags":[],"cell_id":"c855a98449764f1fae0023d204c34e58","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"classes_cogroo=['n', 'prop', 'art', 'pron', 'pron-pers', 'pron-det',\n                'pron-indp', 'adj', 'n-adj', 'v', 'v-fin', 'v-inf',\n                'v-pcp', 'v-ger', 'num', 'prp', 'adj', 'conj',\n                'conj-s','conj-c', 'intj', 'adv', 'xxx']","metadata":{"tags":[],"cell_id":"627bdfe7331048f0a064a1c207776601","source_hash":"5e1ba59c","execution_millis":0,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Criação do dicionário pos_tags da classe Cogroo, para traduzir as classificações geradas pelo CoGrOO para um formato legível em português:","metadata":{"tags":[],"cell_id":"0aac910e412e45988e42e7d904cc09ec","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def _pos_tags(self):\n    pos = {}\n    pos.update({\"n\": \"substantivo\"})\n    pos.update({\"prop\": \"nome próprio\"})\n    pos.update({\"art\": \"artigo\"})\n    pos.update({\"pron\": \"pronome\"})\n    pos.update({\"pron-pers\": \"pronome pessoal\"})\n    pos.update({\"pron-det\": \"pronome determinativo\"})\n    pos.update({\"pron-indp\": \"substantivo/pron-indp\"})\n    pos.update({\"adj\": \"adjetivo\"})\n    pos.update({\"n-adj\": \"substantivo/adjetivo\"})\n    pos.update({\"v\": \"verbo\"})\n    pos.update({\"v-fin\": \"verbo finitivo\"})\n    pos.update({\"v-inf\": \"verbo infinitivo\"})\n    pos.update({\"v-pcp\": \"verbo particípio\"})\n    pos.update({\"v-ger\": \"verbo gerúndio\"})\n    pos.update({\"num\": \"numeral\"})\n    pos.update({\"prp\": \"preposição\"})\n    pos.update({\"adj\": \"adjetivo\"})\n    pos.update({\"conj\": \"conjunção\"})\n    pos.update({\"conj-s\": \"conjunção subordinativa\"})\n    pos.update({\"conj-c\": \"conjunção coordenativa\"})\n    pos.update({\"intj\": \"interjeição\"})\n    pos.update({\"adv\": \"advérbio\"})\n    pos.update({\"xxx\": \"outro\"})\n    return pos\n\n# pos: \"part of speech\"\npos = cogroo.pos_tags","metadata":{"tags":[],"cell_id":"9981e0d5960742c0bbca2b2c8a1a70a3","source_hash":"c88b9262","execution_millis":0,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Análise morfológica do corpus jornalístico\nAnálise do cogroo do corpus jornalístico, gerando a matriz tagged_j, incluindo apenas palavras e caracteres com classificações válidas:","metadata":{"tags":[],"cell_id":"f6326efc94674b6fb59bf8762aac9f70","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"doc_j = cogroo.analyze(str(corpus_j.raw()))\n\nsents_j = []\n\nfor st_j in doc_j.sentences:\n    sents_j=sents_j+st_j.tokens\n\ntagged_j = []\n\nfor tokens in sents_j:\n    aux = re.split(r'#',str(tokens))\n    aux2 = re.split(r' ',aux[1])\n    if(aux2[0] in classes_cogroo):\n        tagged_j = tagged_j + [(aux[0],aux2[0],aux2[1])]\n\nprint(tagged_j, end='')","metadata":{"tags":[],"cell_id":"88abeceff78f4056ba7de4437127337b","source_hash":"53e5e4c4","output_cleared":true,"execution_millis":49410,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"doc = cogroo.analyze(texto_jornalistico)\n\nsents = []\n\nfor st in doc.sentences:\n    sents=sents+st.tokens   \n\ntagged_j = []\n\nfor tokens in sents:\n    aux = re.split(r'#',str(tokens))\n    aux2 = re.split(r' ',aux[1])\n    if(aux2[0] in classes_cogroo):\n        tagged_j = tagged_j + [(aux[0],aux2[0],aux2[1])]\n\ndoc = cogroo.analyze(texto_jornalistico_pt2)\n\nsents = []\n\nfor st in doc.sentences:\n    sents=sents+st.tokens   \n\nfor tokens in sents:\n    aux = re.split(r'#',str(tokens))\n    aux2 = re.split(r' ',aux[1])\n    if(aux2[0] in classes_cogroo):\n        tagged_j = tagged_j + [(aux[0],aux2[0],aux2[1])]\n\nprint(tagged_j, end='')\n","metadata":{"tags":[],"cell_id":"c6b2220b96d64425b2485cae404a3a5e","source_hash":"7b3ad0db","is_code_hidden":false,"output_cleared":true,"execution_millis":0,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Análise morfológica do corpus científico\nAnálise do cogroo do corpus científico, gerando a matriz tagged_c, incluindo apenas palavras e caracteres com classificações válidas:","metadata":{"tags":[],"cell_id":"a1a0fb6e10104ea9954c152766ca48ad","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"doc_c = cogroo.analyze(str(corpus_c.raw()))\n\nsents_c = []\n\nfor st_c in doc_c.sentences:\n    sents_c=sents_c+st_c.tokens\n\ntagged_c = []\n\naux=''\naux2=''\nfor tokens in sents_c:\n    aux = re.split(r'#',str(tokens))\n    aux2 = re.split(r' ',aux[1])\n    if(aux2[0] in classes_cogroo):\n        tagged_c = tagged_c + [(aux[0],aux2[0],aux2[1])]\n\nprint(tagged_c, end='')","metadata":{"tags":[],"cell_id":"44625812e3044f2a99b8488d104ce8b2","source_hash":"89089557","output_cleared":true,"execution_millis":626198,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Geração dos gráficos de distribuição de frequência\n","metadata":{"tags":[],"cell_id":"f1ffdedd551c4266bac3a711b62f3a00","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Importação das ferramentas necessárias\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist","metadata":{"tags":[],"cell_id":"d03f2c38923a49d7a6ba21cbadfed7df","source_hash":"8df61830","execution_millis":5,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Frequência de cada classe morfológica","metadata":{"tags":[],"cell_id":"82d27434235542328c90736495a495c5","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Texto jornalístico","metadata":{"tags":[],"cell_id":"5c8aab04043c45cc9caf4098c77dae2e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nclassificacoes_j = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_j:\n    classificacoes_j  = classificacoes_j + tagged_j[i][1] + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_j = word_tokenize(classificacoes_j)\n\n#Usar o dicionário pos para traduzir as classificações\n# para um formato legível\ni = 0\nfor x in tokens_j:\n    tokens_j[i] = pos[tokens_j[i]]\n    i = i + 1\n\n#Gerar e apresentar a distribuição de frequência\nfDist_class_j = FreqDist(word for word in tokens_j)\n\nfDist_class_j","metadata":{"tags":[],"cell_id":"682b15da45dd4917aa7f448172299e44","source_hash":"b8ff5c4a","is_code_hidden":false,"output_cleared":true,"execution_millis":122,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nltk\n\nx=fDist_class_j.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Frequência de classes morfológicas - jornalístico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Classes')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"a095da3540b74e9f81978b2ff221e31b","source_hash":"1deeadec","is_code_hidden":false,"output_cleared":true,"execution_millis":577,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Texto científico","metadata":{"tags":[],"cell_id":"96587070c99742948e550e420200d037","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nclassificacoes_c = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\n\nfor x in tagged_c:\n    if not ((tagged_c[i][0]=='São' and tagged_c[i+1][0]=='Paulo')\n        or (tagged_c[i][0]=='São' and tagged_c[i+1][0]=='Bernardo')):\n            classificacoes_c  = classificacoes_c + tagged_c[i][1] + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_c = word_tokenize(classificacoes_c)\n\n#Usar o dicionário pos para traduzir as classificações\n# para um formato legível\ni = 0\nfor x in tokens_c:\n    tokens_c[i] = pos[tokens_c[i]]\n    i = i + 1\n\n#Gerar e apresentar a distribuição de frequência\nfDist_class_c = FreqDist(word for word in tokens_c)\n\nfDist_class_c","metadata":{"tags":[],"cell_id":"88715fea735248459f018bc62f13f072","source_hash":"bac8f442","output_cleared":true,"execution_millis":4178,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nltk\n\nx=fDist_class_c.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Frequência de classes morfológicas - científico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Classes')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"b001e7f26d4e43d98ee9177d938c0f54","source_hash":"4a2232bc","output_cleared":true,"execution_millis":595,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Substantivos mais comuns","metadata":{"tags":[],"cell_id":"e68dcbf12922443f856044200b017fc8","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Texto jornalístico","metadata":{"tags":[],"cell_id":"e1d42fb50fd94825a2328f5f5b7ef02f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string da classe\nsubstantivos_j = ''\n\n#Colocar nessa string as palavras lematizadas que correspondem\n# à classe desejada\ni = 0\nfor x in tagged_j:\n    if (pos[ tagged_j[i][1] ] == 'substantivo'):\n        substantivos_j  += cogroo.lemmatize( tagged_j[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar a string\ntokens_j = word_tokenize(substantivos_j)\n\n#Gerar a distribuição de frequência\nfDist_subst_j = FreqDist(word for word in tokens_j)\n\nfDist_subst_j","metadata":{"tags":[],"cell_id":"417e3cffc1934516ac4b080b62bc7a9e","source_hash":"94cee94e","is_code_hidden":false,"output_cleared":true,"execution_millis":4522,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_subst_j.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Substantivos mais comuns - jornalístico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Substantivo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"df56a11f8c1d49ca81a284906f0f3a28","source_hash":"297f766f","is_code_hidden":false,"output_cleared":true,"execution_millis":577,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Texto científico","metadata":{"tags":[],"cell_id":"c0468557a9f74ee189570f555e89216c","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nsubstantivos_c = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_c:\n    if (pos[ tagged_c[i][1] ] == 'substantivo'):\n        substantivos_c  += cogroo.lemmatize( tagged_c[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_c = word_tokenize(substantivos_c)\n\n#Gerar e apresentar a distribuição de frequência\nfDist_subst_c = FreqDist(word for word in tokens_c)\n\nfDist_subst_c","metadata":{"tags":[],"cell_id":"bc3a29f0329246e39bedc8d4f0a25ce0","source_hash":"577b4eb0","is_code_hidden":false,"output_cleared":true,"execution_millis":22772,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_subst_c.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Substantivos mais comuns - científico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Substantivo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"7fcf7b54e71c41b88ca8eefdb0412e3e","source_hash":"70484ae8","is_code_hidden":false,"output_cleared":true,"execution_millis":520,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Adjetivos mais comuns","metadata":{"tags":[],"cell_id":"0637495053a447d08b81a2d736c1112a","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Texto jornalístico","metadata":{"tags":[],"cell_id":"c2812263fdae44bfa3ec45a43b88370d","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nadjetivos_j = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_j:\n    if (pos[ tagged_j[i][1] ] == 'adjetivo'):\n        adjetivos_j  += cogroo.lemmatize( tagged_j[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_j = word_tokenize(adjetivos_j)\n\n#Gerar e apresentar a distribuição de frequência\nfDist_adj_j = FreqDist(word for word in tokens_j)\n\nfDist_adj_j","metadata":{"tags":[],"cell_id":"3242edf446d148959fdaf5d3e19559c8","source_hash":"e9535eba","is_code_hidden":false,"output_cleared":true,"execution_millis":899,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_adj_j.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Adjetivos mais comuns - jornalístico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Adjetivo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"f3644be43a294bc2859ac8d6de3e5cb7","source_hash":"ff84043c","is_code_hidden":false,"output_cleared":true,"execution_millis":565,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Texto científico","metadata":{"tags":[],"cell_id":"23529c93bb65469786bb01762f69fbc7","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nadjetivos_c = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_c:\n    if (pos[ tagged_c[i][1] ] == 'adjetivo'):\n        adjetivos_c  += cogroo.lemmatize( tagged_c[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_c = word_tokenize(adjetivos_c)\n\n#Gerar e apresentar a distribuição de frequência\nfDist_adj_c = FreqDist(word for word in tokens_c)\n\nfDist_adj_c","metadata":{"tags":[],"cell_id":"b600528663934a38afbdb0475c1fa81d","source_hash":"6646232e","is_code_hidden":false,"output_cleared":true,"execution_millis":9079,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_adj_c.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Adjetivos mais comuns - científico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Adjetivo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\nplt.show()","metadata":{"tags":[],"cell_id":"43330a4e0f6c4e47bc260521ef102960","source_hash":"771d8222","is_code_hidden":false,"output_cleared":true,"execution_millis":546,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Verbos mais comuns","metadata":{"tags":[],"cell_id":"3771522217b3404492840d26973184e0","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Texto jornalístico","metadata":{"tags":[],"cell_id":"f294cb52f81445b6880f529d45a7c179","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nverbos_j = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_j:\n    if (pos[ tagged_j[i][1] ] == 'verbo finitivo' \n    and tagged_j[i+1][0]!='Paulo'):\n        verbos_j  += cogroo.lemmatize( tagged_j[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_j = word_tokenize(verbos_j)\n\n#Gerar e apresentar a distribuição de frequência\nfDist_verb_j = FreqDist(word for word in tokens_j)\n\nfDist_verb_j","metadata":{"tags":[],"cell_id":"6e22a6e125fe4c109076cb41b4a7209a","source_hash":"504a7b82","is_code_hidden":false,"output_cleared":true,"execution_millis":37,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_verb_j.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Verbos mais comuns - jornalístico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Verbo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\n\nplt.show()","metadata":{"tags":[],"cell_id":"d529149fee904abf8856b5e608bf4cb9","source_hash":"4ab63eb","is_code_hidden":false,"output_cleared":true,"execution_millis":584,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Texto científico","metadata":{"tags":[],"cell_id":"1a937011c9be47f199b1eda60a7aa5d0","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#Criacao de uma string classificações\nverbos_c = ''\n\n#Colocar nessa string a classificacao morfologica de cada palavra\n# na matriz etiquetada do corpus\ni = 0\nfor x in tagged_c:\n    if pos[ tagged_c[i][1] ] == 'verbo finitivo' \n    and tagged_c[i+1][0]!='Paulo':\n        verbos_c  += cogroo.lemmatize( tagged_c[i][0] ) + ' '\n    i = i + 1\n\n#Tokenizar essa string, sendo identificada cada palavra/classificação\n# como elemento da lista tokens\ntokens_c = word_tokenize(verbos_c)\n\n#Gerar e apresentar a distribuição de frequência\nfDist_verb_c = FreqDist(word for word in tokens_c)\n\nfDist_verb_c","metadata":{"tags":[],"cell_id":"2cb0c0c8802f48c4ba84dbc6141b2708","source_hash":"585541f5","is_code_hidden":false,"output_cleared":true,"execution_millis":255,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=fDist_verb_c.most_common(20)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]\n\nplt.rcParams[\"figure.figsize\"] = [16,8]\n\nmatplotlib.rcParams.update({'font.size': 15})\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Ocorrências')\n\nax.set_title('Verbos mais comuns - científico')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Verbo primitivo')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\n\nfig.tight_layout()\n\nplt.show()","metadata":{"tags":[],"cell_id":"379f7b5abe5d425ba05d13203cb637cd","source_hash":"503c61e1","is_code_hidden":false,"output_cleared":true,"execution_millis":528,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Gráficos sem Stopwords","metadata":{"tags":[],"cell_id":"4e256e53fc5842cfbc21ac6dbe5f9306","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#teste de stop words em português\nimport nltk\nnltk.download('stopwords') \nfrom nltk.corpus import stopwords\nstopwords=nltk.corpus.stopwords.words('portuguese')\nstopwords[:100]","metadata":{"tags":[],"cell_id":"7c89d731ca36471fb7f9112a32dd3e95","source_hash":"c312a625","output_cleared":true,"execution_millis":37,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Importação de stop words em português\nimport nltk\nnltk.download('stopwords') \nfrom nltk.corpus import stopwords\nstopwords=nltk.corpus.stopwords.words('portuguese')\n\n# distribuição de Frequencia do texto jornalístico\n# sem stopwords\nfd_j2 = nltk.FreqDist(w.lower() for w\n in corpus_j.words() if w not in stopwords)\n\nfd_j2.most_common(30)","metadata":{"tags":[],"cell_id":"6da254141cad483ebd03cbfd5654dd67","source_hash":"9e5285a6","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Frequencia de palavaras do corpus_j que não são stopwords\ndef content_fraction(corpus_j):\n content = [w for w in corpus_j \n if w.lower() not in stopwords]\n return len(content) / len(corpus_j)\ncontent_fraction(corpus_j.words())","metadata":{"tags":[],"cell_id":"a2c97d7b82a541e7807ab1cd5d13f203","source_hash":"db394011","output_cleared":true,"execution_millis":102,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fd_j2\nx=fd_j2.most_common(30)\ntypes=[w for (w,f) in x]\nfreq=[f for (w,f) in x]","metadata":{"tags":[],"cell_id":"e606142cdffc47a18db3566dcb769a66","source_hash":"a38d5a3","execution_millis":3,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nltk\n\nx = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\nfig, ax = plt.subplots()\n\nrects1 = ax.bar(x,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Frequência')\n\nax.set_title('Frequência x Types')\nax.set_xticks(x)\nax.set_xticklabels(types)\nax.set_xlabel('Types')\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\nplt.show()","metadata":{"tags":[],"cell_id":"c4852d7302644c87be367e0adeb3e875","source_hash":"e42da633","output_cleared":true,"execution_millis":621,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# distribuição de Frequencia do artigos científico\n# sem stopwords\nfd_c2 = nltk.FreqDist(w.lower() for w in \ncorpus_c.words() if w not in stopwords)\nfd_c2.most_common(30)","metadata":{"tags":[],"cell_id":"f6183bccb2a24d90a18a498556145e20","source_hash":"b8bc65ca","output_cleared":true,"execution_millis":1626,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Frequencia de palavras do corpus_c que não são stopwords\ndef content_fraction(corpus_c):\n content = [w for w in corpus_c if w.lower() not in stopwords]\n return len(content) / len(corpus_c)\ncontent_fraction(corpus_c.words())","metadata":{"tags":[],"cell_id":"c57614aa217a48c4836e1954aaef0ad9","source_hash":"f9d45e5c","output_cleared":true,"execution_millis":1374,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fd_c2\ny=fd_c2.most_common(30)\ntypes=[w for (w,f) in y]\nfreq=[f for (w,f) in y]","metadata":{"tags":[],"cell_id":"ff2f77eca12d446d8c0c0667fccf4a45","source_hash":"aeff7f6c","execution_millis":3,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nltk\n\ny = np.arange(len(types))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(y,freq, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Frequência')\n\nax.set_title('Frequência x Types')\nax.set_xticks(y)\nax.set_xticklabels(types)\nax.set_xlabel('Types')\n\nax.legend()\nax.tick_params(axis ='x', rotation = 90)\nfig.tight_layout()\n\nplt.show()","metadata":{"tags":[],"cell_id":"aab6dd0441da4be99ef28d329532d28e","source_hash":"713b5aa","output_cleared":true,"execution_millis":601,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Análise de palavras chave dos textos jornalísticos","metadata":{"tags":[],"cell_id":"ea5cdb9aa8644e9c9c24a27dfab8fb76","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import nltk\nfrom nltk import ngrams\ntks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\nngramas","metadata":{"tags":[],"cell_id":"ce615bb94d184556ae2805ad955ffd70","source_hash":"194ebb64","execution_start":1619031747828,"execution_millis":49,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Frequencia de palavras com SER no jornalistico","metadata":{"tags":[],"cell_id":"0033a62fd13942e3b1f9884a9244078e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\npalavras = ''\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(bigramas)):\n  if cogroo.lemmatize(bigramas[i][0]) == 'ser' \n    and bigramas[i+1][0]!='Paulo' \n    and bigramas[i+1][0]!='Bernardo':\n      palavras = palavras + cogroo.lemmatize(bigramas[i][1]) + ' '\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1\n\n\npalavras_tokens = word_tokenize(palavras)\n\nfDist_palavras = FreqDist(word.lower() for word in palavras_tokens)\n\nfDist_palavras","metadata":{"tags":[],"cell_id":"4b3ead7eb35846fdbdecc4aaa7f7785b","source_hash":"da0830d8","output_cleared":true,"execution_millis":99,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Frequencia de palavras com SER no cientifico","metadata":{"tags":[],"cell_id":"66fe630b54e84518b99a6cdc114548da","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_c.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\npalavras = ''\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(bigramas)):\n  if cogroo.lemmatize(bigramas[i][0]) == 'ser' \n    and bigramas[i+1][0]!='Paulo' \n    and bigramas[i+1][0]!='Bernardo':\n      palavras = palavras + cogroo.lemmatize(bigramas[i][1]) + ' '\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1\n\n\npalavras_tokens = word_tokenize(palavras)\n\nfDist_palavras = FreqDist(word.lower() for word in palavras_tokens)\n\nfDist_palavras","metadata":{"tags":[],"cell_id":"a73cd02d6d4f4352952e59ad548ef9eb","source_hash":"cf60b45c","output_cleared":true,"execution_millis":96800,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Frequencia de palavras com IR no jornalistico","metadata":{"tags":[],"cell_id":"1f53c1b509bc420988a36f760aeaa7b2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\npalavras = ''\n\ntypes=list(set(tks))\n\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(bigramas)):\n  if cogroo.lemmatize(bigramas[i][0]) == 'ir':\n        palavras = palavras + cogroo.lemmatize(bigramas[i][1]) + ' '\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1\n\n\npalavras_tokens = word_tokenize(palavras)\n\nfDist_palavras = FreqDist(word.lower() for word in palavras_tokens)\n\nfDist_palavras","metadata":{"tags":[],"cell_id":"5c40359d7f6944d2b498905b0d99a6a8","source_hash":"f1662217","output_cleared":true,"execution_millis":96,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Frequencia de palavras com IR no cientifico","metadata":{"tags":[],"cell_id":"2b257078f8b644b99da7724ee9808528","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_c.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\npalavras = ''\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(bigramas)):\n  if cogroo.lemmatize(bigramas[i][0]) == 'ir':\n        palavras = palavras + cogroo.lemmatize(bigramas[i][1]) + ' '\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1\n\n\npalavras_tokens = word_tokenize(palavras)\n\nfDist_palavras = FreqDist(word.lower() for word in palavras_tokens)\n\nfDist_palavras","metadata":{"tags":[],"cell_id":"e6cf8bf6ba4440e3bba53fd33e79e898","source_hash":"1f496762","output_cleared":true,"execution_millis":100198,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exemplos de frases com verbo IR: Jornalistico","metadata":{"tags":[],"cell_id":"a5cd9140dd7f4fb2b8ab91d79438316f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if cogroo.lemmatize(ngramas[i][0]) == 'ir':\n    print(ngramas[i])\n    contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n    contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"82faf103ef214be198904ff79d51cb3a","source_hash":"fc46ca5a","is_code_hidden":false,"output_cleared":true,"execution_millis":10348,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exemplos de frases com verbo IR: Científico","metadata":{"tags":[],"cell_id":"01627bae0d65489d95a3869f8ef73967","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_c.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if cogroo.lemmatize(ngramas[i][0]) == 'ir':\n    print(ngramas[i])\n    contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n    contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"e6234d2c09064bb689c7a4727499b0c0","source_hash":"4fb430a4","is_code_hidden":false,"output_cleared":true,"execution_millis":106141,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exemplos de frases com verbo SER: Jornalistico","metadata":{"tags":[],"cell_id":"8724ec0f34094b48bb957e1bb79b8849","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if cogroo.lemmatize(ngramas[i][0]) == 'ser' \n    and ngramas[i+1][0]!='Paulo' \n    and ngramas[i+1][0]!='Bernardo':\n      print(ngramas[i])\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"0db32ca61a904810a9fed794a818dff9","source_hash":"e7ef6aeb","is_code_hidden":false,"output_cleared":true,"execution_millis":175,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exemplos de frases com verbo SER: Científico","metadata":{"tags":[],"cell_id":"f774d3f4658d45e6abb26705675ac43b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"tks=corpus_c.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if cogroo.lemmatize(ngramas[i][0]) == 'ser' \n    and ngramas[i+1][0]!='Paulo' \n    and ngramas[i+1][0]!='Bernardo':\n      print(ngramas[i])\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n      contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"06028cba484d4893acf9038f87fc9f4c","source_hash":"9d9ea35","is_code_hidden":false,"output_cleared":true,"execution_millis":39243,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Análises adicionais: Palavras associadas a Zona, Avenida e Rua","metadata":{"tags":[],"cell_id":"98879329d97e4801843f4b53aca2416a","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import nltk\nfrom nltk import word_tokenize\nfrom nltk.probability import FreqDist\n\n\ntks=corpus_j.words()\nngramas = list(ngrams(tks, 4))\nbigramas = list(ngrams(tks, 2))\n\npalavras = ''\n\ntypes=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(bigramas)):\n  if bigramas[i][0] == 'zona':\n        print(bigramas[i])\n        palavras = palavras + bigramas[i][1] + ' '\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1\n\n        palavras_tokens = word_tokenize(palavras)\n\nfDist_palavras = FreqDist(word.lower() for word in palavras_tokens)\n\nfDist_palavras","metadata":{"tags":[],"cell_id":"a321188f763546f198d68e07b5b5febb","source_hash":"67795c13","output_cleared":true,"execution_start":1619037713485,"execution_millis":195,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"types=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if ngramas[i][0] == 'avenida':\n        print(ngramas[i])\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"e15eb90bf895412da1f2c819cf83ef53","source_hash":"88625b8c","output_cleared":true,"execution_millis":8,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"types=list(set(tks))\ncontagem=np.zeros((len(types),len(types)))\ndicio={}\nfor i in range(len(types)):\n  dicio[types[i]]=i\nfor i in range(len(ngramas)):\n  if ngramas[i][0] == 'rua':\n        print(ngramas[i])\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][0]]] += 1\n        contagem[dicio[ngramas[i][1]]][dicio[ngramas[i][2]]] += 1","metadata":{"tags":[],"cell_id":"45cfbed9b2be4072bc97ff383c524083","source_hash":"25020aae","output_cleared":true,"execution_start":1619031776431,"execution_millis":31,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=162f482c-e397-45e6-9a74-fda6ea1a664a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"5e5db91745e94fe9a398e3ba118a61d6","deepnote_execution_queue":[]}}